---
title: "P8105 HW3"
author: "Elaine Yanxi Chen"
date: "`r Sys.Date()`"
output: github_document
---

## Packages and settings

First we load the packages necessary to knit this document.

```{r packages and settings, message = FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


# Problem 1: `instacart`

## Import data

```{r load instacart}
data("instacart")
```

## Describe the dataset

* This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns, with each row representing a single product from an instacart order.

* Variables include identifiers for user, order, and product; the order in which each product was added to the cart. There are several order-level variables, describing the day and time of the order, and number of days since prior order. Then there are several item-specific variables, describing the product name (e.g. Yogurt, Avocado), department (e.g. dairy and eggs, produce), and aisle (e.g. yogurt, fresh fruits), and whether the item has been ordered by this user in the past. 

* In total, there are `r instacart %>% select(product_id) %>% distinct %>% count` products found in `r instacart %>% select(user_id, order_id) %>% distinct %>% count` orders from `r instacart %>% select(user_id) %>% distinct %>% count` distinct users.

## Answer questions

* How many aisles are there, and which aisles are the most items ordered from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

There are `r instacart %>% select(aisle_id) %>% distinct %>% count` aisles, and the most items are ordered from the fresh vegetables and fresh fruits aisles. 

* Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r}
instacart %>% 
   count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

* Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r}
instacart %>% 
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>% 
  knitr::kable()
```

* Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r}
instacart %>% 
  filter(product_id == c(3798, 17334)) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```

Note that there are two names: Pink Lady Apples and Pink Lady (Cripps) Apples. Not sure if they are the same product, but they do have different `product_id`, so will use that to filter (both give the same tibble).


# Problem 2: Accelerometer

## Import and tidy data

```{r clean accel}
accel_data = read_csv(file = "./data/accel_data.csv") %>% 
  janitor::clean_names()

accel_df = accel_data %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "min_of_day",
    values_to = "activity_count",
    names_prefix = "activity_"
  ) %>% 
  rename(dow = day) %>% 
  mutate(weekend = case_when(
    dow %in% c("Saturday", "Sunday") ~ "weekend",
    dow != c("Saturday", "Sunday") ~ "weekday",
    TRUE ~""
  ),
  min_of_day = as.numeric(min_of_day))


```

* Load, tidy, and otherwise wrangle the data. 

  * Dataset was transformed using `pivot_longer` so that each row represents the activity count for a single minute in a 24-hour day.

* Include all originally observed variables and values.

* Include a weekday vs weekend variable.

* Encode data with reasonable variable classes.

  * `day` and `weekend` are coded as characters, while the rest of the variables are coded as numeric.


## Describe the data

Describe the resulting dataset (e.g. what variables exist, how many observations, etc).

* This dataset contains `r nrow(accel_df)` rows and `r ncol(accel_df)` columns, with each row representing the activity count for a single minute in a 24-hour day for the 63-year-old male.

* Variables include identifiers for the day, the minute, and the corresponding activity count. There are several day-level variables,
describing which day (`day_id`)or which week (`week`) the activity count is from, out of the five week data collection period. It also describes which day of the week the measurement was from (`dow`) and whether it's a weekday or a weekend (`weekend`). And then there is the minute-specific variable (`min_of_day`) that specifies the minute of the activity count measurement, starting at midnight of a 24-hour day. Finally, we have the activity count (`activit_count`) measured by the accelerometers for each specific minute. 

* In total, there are activity counts from `r accel_df %>% select(min_of_day) %>% distinct %>% count` minutes each day for a total of `r accel_df %>% select(day_id) %>% distinct %>% count` days spanning `r accel_df %>% select(week) %>% distinct %>% count` weeks.


## Total activity over the day

We want to aggregate across minutes to create a total activity variable for each day and show results in a table.

```{r}
accel_df %>% group_by(week, day_id, dow, weekend) %>% summarize(total_activity = sum(activity_count)) %>% 
  knitr::kable()
```

To look at trends, it is better to pipe the results into  `ggplot2`.

First we can look at whether the total activity changes as the weeks go on. It does not seem like there is any obvious trend, maybe a slight decrease of total activity near the end of five-week period. There are two notable days with very low total activity.  
```{r}
accel_df %>% group_by(week, day_id, dow, weekend) %>% summarize(total_activity = sum(activity_count)) %>% 
  ggplot(aes(x = day_id, y = total_activity)) +
  geom_point() + geom_line()
```

Next, we can compare weekday over weekend. However, this comparison is also significantly affected by the two Saturday outliers. 

```{r}
accel_df %>% group_by(week, day_id, dow, weekend) %>% summarize(total_activity = sum(activity_count)) %>% 
  ggplot(aes(x = weekend, y = total_activity)) +
  geom_boxplot()
```

We can also compare each day of the week. If we look at this plot, it seems like in general, weekends (Fridays, Saturdays, Sundays) have slightly higher total activity than the weekdays. We see the Saturday is significantly affected by the two extremely low measurements. 

```{r}
accel_df %>% group_by(week, day_id, dow, weekend) %>% summarize(total_activity = sum(activity_count)) %>% 
  ggplot(aes(x = dow, y = total_activity)) +
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## 24-hour activity time courses

Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week.

```{r}
accel_df %>% group_by(week, day_id) %>% 
  ggplot(aes(x = min_of_day, y = activity_count, colour = dow)) +
  geom_line() +
  labs(
    title = "24-hour activity time course plot",
    x = "Hour of the day (hr)",
    y = "Activity count",
    colour = "Day of the week"
  ) +
   scale_x_continuous(
    breaks = c(0, 120, 240, 360, 480, 600, 720, 840, 960, 1080, 1200, 1320, 1440),
    labels = c("0", "2", "4", "6", "8", "10", "12", "14", "16", "18", "20", "22", "24")) +
  scale_y_continuous(
    breaks = c(1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000)
  )
```

Minutes on the x-axis were converted to hours of the day to help better read and interpret the plot. The activity count is generally low (around 1000) from hours 0 - 6 in the morning, which corresponds to the time of sleep. The activity count picks up from around 6 am, and is much higher during the day till around hour 23 or 11 pm at night. There are several notable activity count peaks. There are several peaks around 7 - 8 am, 10 am - 12 pm, around 4 pm, and most notably, around 8 - 10 pm. 


# Problem 3: NY NOAA data

## Import data

```{r}
data("ny_noaa")
```

## Exploration of the dataset

* This dataset contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns, with each row representing the weather parameters recorded from a weather station in the state of New York on the specific date. 

* Variables include identifiers for the weather station (`id`), the date of observation (`date`), and the corresponding weather observations. 

* There are several observation-level variables, describing the amount of precipitation (`prcp`), the amount of snowfall and snow depth (`snow` and `snwd`), and the minimum and maximum temperature of the day (`tmin` and `tmax`). 

* In total, there are weather observations recorded from `r ny_noaa %>% select(id) %>% distinct %>% count` weather stations in the state of New York from January 1st, 1981 to December 31st, 2010. 